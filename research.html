<!DOCTYPE html>
<html lang="en">

<head>
  <title>Research</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Favicon -->
  <link rel="icon" type="image/x-icon" href="favicon.png">

  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css">
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"></script>
  <style>
    /* Custom Navbar Styles */
    .navbar {
      background-color: #3f4044 !important; /* Dark gray */
    }

    .navbar a.navbar-brand, .navbar-nav .nav-link {
      color: white !important;
    }

    .navbar a.navbar-brand:hover, .navbar-nav .nav-link:hover {
      color: #fa4616 !important; /* Red-orange on hover */
    }
  </style>
</head>


<body>
<!-- A grey horizontal navbar that becomes vertical on small screens -->
<nav class="navbar navbar-expand-sm bg-dark navbar-dark">
  <div class="container-fluid">
    <a class="navbar-brand" href="index.html">Home</a>
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#collapsibleNavbar">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="collapsibleNavbar">
      <ul class="navbar-nav">
        <li class="nav-item">
          <a class="nav-link" href="about.html">About</a>
        </li>
        <li class="nav-item">
          <a class="nav-link active" href="#">Research</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="RTL_CV.pdf">CV</a>
        </li> 
      </ul>
    </div>
  </div>
</nav>

<div class = "container-fluid p-4" style="max-width:900px;">
  <!-- <h1>List of Research</h1> -->

  <!-- <h3> Publications </h3> -->

  <h3>Research Papers</h3>

  <p>
      Multi-Agent Data Collection and Delivery Under Intermittent Sensing with Deep Reinforcement Learning
    </a>
  </p>
  <p>
     <strong>Robert T. Lattus</strong>, John M. Shea (2026)
  </p>
  <p>
    <em>2026 IEEE Wireless Communications and Networking Conference</em>
  </p>
  <p style="margin-left: 20px; font-size: 0.9em;">
    <strong>Abstract:</strong>   We consider a scenario in which multiple mobile agents collect data from a fixed number of evasive phenomena in a prescribed environment. Once data is collected, the agents travel to one of several fixed access points (APs) to deliver the data. We consider a distributed setting with no direct communication among the agents. The agents are hindered both by noise in their sensing mechanisms and intermittent ability to collect sensing measurements due to environmental factors. We cast this problem as a partially observable Markov decision process (POMDP) and use particle filters to perform belief-state estimation. We propose two methods to estimate the locations of the phenomena during periods where they are not directly observable. Using proximal policy optimization (PPO) with centralized training, decentralized execution (CTDE), we train each agent to provide reliable, real time data collection and delivery to the APs. We compare both belief-state estimation methods integrated with PPO, demonstrating strong cooperation, even in the noisy, distributed setting.
  </p>


  <p>
      Proximal Policy Optimization for Coordination of Distributed Agents in a Cooperative Jamming Scenario
    </a>
  </p>
  <p>
     <strong>Robert T. Lattus</strong>, John M. Shea (2026)
  </p>
  <p>
    <em>2026 IEEE International Conference on Computing, Networking, and Communications</em>
  </p>
  <p style="margin-left: 20px; font-size: 0.9em;">
    <strong>Abstract:</strong> Drones and other mobile robots are playing an increasing role in modern warfare. Jamming is a key technology to protect certain areas from intrusion by adversaries of these types. In this paper, we consider protecting a sensitive area from mobile adversaries that are operating in a leader-follower configuration and coordinated over a wireless channel. The protected area contains agents equipped with low-power RF transmitters and highly directional antennas whose goal is to block the operations of the adversaries by disrupting their ability to communicate. The fact that such antennas concentrate the RF power over relatively small sectors makes evasive maneuvers by the adversaries more effective. We consider a scenario in which the agents cannot directly communicate, and thus they must decide the orientations of their jamming beams in a decentralized fashion. Furthermore, the adversaries' locations must be inferred from RF or RADAR measurements that are corrupted by noise. We cast this problem as a continuous-observation, partially-observable Markov decision process. Each agent is trained using multi-agent proximal policy optimization with centralized training, decentralized execution. We compare our results to deterministic and independent approaches, demonstrating the benefits of stochastic policies for distributed cooperation.
  </p>


  <p>
    <a href="https://ieeexplore.ieee.org/abstract/document/11139970" class="maroon-link">
      Multi-Agent Data Collection with Distributed Stochastic Coordination for Wireless Data Delivery
    </a>
  </p>
  <p>
     <strong>Robert T. Lattus</strong>, John M. Shea (2025)
  </p>
  <p>
    <em>2025 IEEE International Conference on Machine Learning for Communication and Networking</em>
  </p>
  <p style="margin-left: 20px; font-size: 0.9em;">
    <strong>Abstract:</strong> We consider a scenario in which multiple mobile agents are tasked with moving around an area to collect data about some phenomena that occur at random within the prescribed area. The agents must deliver the data by traveling to a location inside the communication range of one of several access points (APs). We consider a fully decentralized setting, in which agents first randomly search the region for phenomena of interest and independently make choices about which APs to travel to once they have data to deliver. In this scenario, multiple agents that observe the same phenomenon may travel to a single AP that they characterize as most ideal, such as in terms of distance or communication capacity. This can cause delays in delivering the data if the communication capacity of the selected AP has to be shared among the agents. If centralized control were used, agents would be assigned to different APs to avoid these delays. We explore the use of stochastic policies to facilitate a form of distributed coordination and demonstrate their advantage over deterministic policies in a simulated environment.
  </p>

  <p>
    <a href="https://doi.org/10.1080/00167428.2021.1947139" class="maroon-link">
      UNDERSTANDING THE SPATIAL PATCHWORK OF PREDICTIVE MODELING OF FIRST WAVE PANDEMIC DECISIONS BY US GOVERNORS
    </a>
   </p>
   <p>
     Patricia Sol√≠s, Gautam Dasarathy, Pavan Turaga, Alexandria Drake, Kevin Jatin Vora, Akarshan Sjasa, Ankith Raaman, Sarbeswar Praharaj, <strong>Robert Lattus</strong> (2023)
  </p>
  <p>
    <em>Examining the COVID Crisis from a Geographical Perspective</em>. Routledge, 2023. 100-123.
  </p>
  <p style="margin-left: 20px; font-size: 0.9em;">
    <strong>Abstract:</strong> The uneven outcomes of the COVID-19 pandemic in the United States can be characterized by its patchwork patterns. Given a weak national coordinated response, state-level decisions offer an important frame for analysis. This article explores how such analysis invokes fundamental geographic challenges related to the modified areal unit problem, and results in scientific predictive models that behave differently in different states. We examined morbidity with respect to state-level policy decisions, by comparing the fit and significance of different types of predictive modeling using data from the first wave of 2020. Our research reflects upon public health literature, mathematical modeling, and geographic approaches in the wake of the underlying complex pattern of drivers, decisions, and their impact on public health outcomes state by statetime line. Contemplating these findings, we discuss the need to improve integration of fundamental geographic concepts to creatively develop modeling and interpretations across disciplines that offer value for both informing and holding accountable decision makers of the jurisdictions in which we live.
  </p>

  <p>
    <a href="https://keep.lib.asu.edu/items/161220" class="maroon-link">
      Characterizing the Performance of Machine Learning Algorithms: A Study and Novel Techniques
    </a>
  </p>
  <p>
     <strong>Lattus, Robert</strong> (2021)
  </p>
  <p>
    <em>Barrett, the Honors College Thesis</em>, Arizona State University
  </p>
  <p style="margin-left: 20px; font-size: 0.9em;">
    <strong>Abstract:</strong> Classification in machine learning is quite crucial to solve many problems that the world is presented with today. Therefore, it is key to understand one's problem and develop an efficient model to achieve a solution. One technique to achieve greater model selection and thus further ease in problem solving is estimation of the Bayes Error Rate. This paper provides the development and analysis of two methods used to estimate the Bayes Error Rate on a given set of data to evaluate performance. The first method takes a "global" approach, looking at the data as a whole, and the second is more "local"--partitioning the data at the outset and then building up to estimation of the three Bayes Error Rate when the dataset is at high dimension, while the other method provides accurate estimation at large sample size. This second conclusion, in particular, can have signification ramifications of "big data" problems, as one would be able to clarify the distribution with an accurate estimation of the Bayes Error Rate by using this method.
  </p>

  <h3>Works in Progress</h3>

  <p>Autonomous Multi-Agent Event-Based Travel with Stochastic Policies (2026) </p>

</div>

</body>
</html>